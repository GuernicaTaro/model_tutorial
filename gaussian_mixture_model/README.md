# Gaussian Mixture Model

混合ガウスモデル(Guassian Mixture Model, GMM)は、有限個の正規分布の重ね合わせを確率分布にもつモデルである。
多峰性のデータのクラスタリングや分類に用いることができる。

## Case 1 : クラスタ数指定あり

アイリスのデータセットに対して、クラスタ数3でGMMによるクラスタリングを行なった。
可視化された結果を観ると、versicolorとvirginicaを判別するのは不良であるが、setosaの判別には成功している。

## Case 2 : クラス多数指定なし

case1 ではクラスタ数を先に与えてクラスタリングしたが、実用的にはクラスタ数がわからない場合が多いだろう。
そこで、クラスタ数を与えずに、最良のクラスタ数を探りながらクラスタリングを行う。

モデルの「最良」を定める主な方法として、最尤推定法と周辺尤度最大化によるものがある。
今回は周辺尤度最大化の哲学に基づいて最良性を定めることとする。

また、予測モデルに使用するモデルの主な流儀として、頻度論によるものとベイズ理論によるものがある。
頻度論では、予測モデルに使用するパラメータは、上述した最良なパラメータθである。
一方で、ベイズ理論では、予測モデルは事後分布をもとに決定される。
今回は頻度論に基づいて予測を行うこととする。

以上の設定においてモデルの評価を行うにはBICを用いるのがよいとされる。
今回のクラスタリングでは共分散行列の選び方を変えた4種類のGMMを用意し、それぞれに対してクラスタ数を1から7の範囲にとって、BICが最低となるモデルを探索した。

結果は、共分散タイプfull、クラスタ数2のモデルが最良となった。
クラスタリング結果は、setocaとそれ以外を分離するものとなった。


## 参考記事
- 実装（クラスタ数指定あり） : https://qiita.com/isuya/items/018a0867bdc95033736d
- 実装（クラスタ数指定なし） : https://akitoshiblogsite.com/python-scikit-learn-gmm/
- 情報量基準まとめ : https://qiita.com/s-yonekura/items/03191bacd6a1c6588b6a
- AICについて : https://qiita.com/fred55/items/c2d884843686f9e1f618
- BICについて : https://qiita.com/fred55/items/c3a4ce1ece9434b2f816

